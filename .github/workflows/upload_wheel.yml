name: Databricks Pytest Integration test.

on:
  push
  
env:
  DATABRICKS_HOST: https://adb-7621144643150231.11.azuredatabricks.net
  #(対象となるWorkspace URLを入力） 
  DATABRICKS_TOKEN: ${{ secrets.DBTOKEN }}
  #先ほど登録したGitHub Secretsを呼び出す

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checks out the repo
        uses: actions/checkout@v2
        #version 2➝4
      
# run_tests.py をDBFS上にアップロード。databricksが提供している upload-dbfs-tempを活用
      - name: Upload main file
        uses: databricks/upload-dbfs-temp@v0
        id: upload_file
        with:
          local-path: test-harness/databricks_test_harness/run_tests.py
          dbfs-temp-dir: 'dbfs:/tmp/jmaru/jobs/myapp/'

# Wheelによるパッケージ化
      - name: Setup python
        uses: actions/setup-python@v2
      - name: Install setuptools
        run: pip install setuptools
      - name: Install wheel
        run: pip install wheel
      - name: Build wheel
        working-directory: ./example
        run:
          python setup.py bdist_wheel
          
# Wheel fileのCopy
      - name: Commit and Push file
        run: |
            git config --global user.email "jung@ap-com.co.jp"
            git config --global user.name "apc-jung"
            git add example/dist/*.whl
            CHANGES=$(git diff --cached)
            if [ -z "$CHANGES" ]; then
              echo "No changes to commit."
            else
              git commit -m "Add built wheel files"
              git pull --rebase origin master
              git push
            fi
            
# Wheel fileのアップロード
      - name: Upload Wheel
        uses: databricks/upload-dbfs-temp@v0
        id: upload_wheel
        with:
          local-path: ./example/dist/databricks_tests_example-0.0.1-py3-none-any.whl
          dbfs-temp-dir: 'dbfs:/tmp/jmaru/jobs/myapp/'

# databricks run submit実行のため、databricks-cli のインストール
      - name: install databricks cli
        run: pip install databricks-cli
       
# run submit(Job API)の実行
      - name: Trigger run submit
        working-directory: ./example
        run:
          databricks runs submit --json-file run_submit.json
